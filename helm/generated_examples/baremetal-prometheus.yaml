---
# Source: provisioner/templates/provisioner.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: local-provisioner-config
  namespace: default
  labels:
    heritage: "Tiller"
    release: "RELEASE-NAME"
    chart: provisioner-2.3.4
data:
  storageClassMap: |
    local-storage:
       hostDir: /mnt/disks
       mountDir: /mnt/disks
       blockCleanerCommand:
         - "/scripts/shred.sh"
         - "2"
       volumeMode: Block
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: local-volume-provisioner
  namespace: default
  labels:
    app: local-volume-provisioner
    heritage: "Tiller"
    release: "RELEASE-NAME"
    chart: provisioner-2.3.4
spec:
  selector:
    matchLabels:
      app: local-volume-provisioner
  template:
    metadata:
      labels:
        app: local-volume-provisioner
    spec:
      serviceAccountName: local-storage-admin
      containers:
        - image: "quay.io/external_storage/local-volume-provisioner:v2.3.4"
          name: provisioner
          securityContext:
            privileged: true
          env:
          - name: MY_NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          - name: MY_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: JOB_CONTAINER_IMAGE
            value: "quay.io/external_storage/local-volume-provisioner:v2.3.4"
          ports:
          - containerPort: 8080
            name: http
          volumeMounts:
            - mountPath: /etc/provisioner/config
              name: provisioner-config
              readOnly: true
            - mountPath: /dev
              name: provisioner-dev
            - mountPath: /mnt/disks
              name: local-storage
              mountPropagation: "HostToContainer"
      volumes:
        - name: provisioner-config
          configMap:
            name: local-provisioner-config
        - name: provisioner-dev
          hostPath:
            path: /dev
        - name: local-storage
          hostPath:
            path: /mnt/disks
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-storage
  labels:
    heritage: "Tiller"
    release: "RELEASE-NAME"
    chart: provisioner-2.3.4
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Delete
---
apiVersion: v1
kind: Service
metadata:
  name: local-volume-provisioner
  namespace: default
  labels:
    app: local-volume-provisioner
    heritage: "Tiller"
    release: "RELEASE-NAME"
    chart: provisioner-2.3.4
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: 8080
      name: http
  selector:
    app: local-volume-provisioner
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: local-volume-provisioner
  namespace: monitoring
  labels:
    app: local-volume-provisioner
    heritage: "Tiller"
    release: "RELEASE-NAME"
    chart: provisioner-2.3.4
    prometheus: kube-prometheus
spec:
  jobLabel: app
  selector:
    matchLabels:
      app: local-volume-provisioner
      release: "RELEASE-NAME"
  namespaceSelector:
    matchNames:
      - default
  endpoints:
    - port: http
      interval: 10s
      scheme: http

---
# Source: provisioner/templates/provisioner-service-account.yaml

apiVersion: v1
kind: ServiceAccount
metadata:
  name: local-storage-admin
  namespace: default
  labels:
    heritage: "Tiller"
    release: "RELEASE-NAME"
    chart: provisioner-2.3.4

---
# Source: provisioner/templates/provisioner-cluster-role-binding.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: local-storage-provisioner-pv-binding
  labels:
    heritage: "Tiller"
    release: "RELEASE-NAME"
    chart: provisioner-2.3.4
subjects:
- kind: ServiceAccount
  name: local-storage-admin
  namespace: default
roleRef:
  kind: ClusterRole
  name: system:persistent-volume-provisioner
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: local-storage-provisioner-node-clusterrole
  labels:
    heritage: "Tiller"
    release: "RELEASE-NAME"
    chart: provisioner-2.3.4
rules:
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: local-storage-provisioner-node-binding
  labels:
    heritage: "Tiller"
    release: "RELEASE-NAME"
    chart: provisioner-2.3.4
subjects:
- kind: ServiceAccount
  name: local-storage-admin
  namespace: default
roleRef:
  kind: ClusterRole
  name: local-storage-provisioner-node-clusterrole
  apiGroup: rbac.authorization.k8s.io

---
# Source: provisioner/templates/namespace.yaml


---
# Source: provisioner/templates/pod-security-policy.yaml


